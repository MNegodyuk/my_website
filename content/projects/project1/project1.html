---
title: "Session 2: Homework 1"
author: "Group A8 (Benedikt Jaletzke, Stanislav Makarov, Mark Negodyuk, Olivia Zhang, Tom Tian, Kateryna Tarasova)"
date: "2020-10-20"
output:
  html_document:
    theme: flatly
    highlight: zenburn
    number_sections: yes
    toc: yes
    toc_float: yes
    code_folding: show
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<div id="where-do-people-drink-the-most-beer-wine-and-spirits" class="section level1">
<h1>Where Do People Drink The Most Beer, Wine And Spirits?</h1>
<p>Back in 2014, <a href="https://fivethirtyeight.com/features/dear-mona-followup-where-do-people-drink-the-most-beer-wine-and-spirits/">fivethiryeight.com</a> published an article on alchohol consumption in different countries. The data <code>drinks</code> is available as part of the <code>fivethirtyeight</code> package. To get the data we install the <code>fivethirtyeight</code> package and upload the data.</p>
<pre class="r"><code>library(fivethirtyeight)
data(drinks)</code></pre>
<p>What are the variable types? Any missing values we should worry about?</p>
<p>We use <code>skim()</code> function to look through the main characteristics of the data set and find whether there are any NAs and what are the variable types:</p>
<pre class="r"><code>skim(drinks)</code></pre>
<table>
<caption>(#tab:glimpse_skim_data)Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">drinks</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">193</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">5</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">character</td>
<td align="left">1</td>
</tr>
<tr class="odd">
<td align="left">numeric</td>
<td align="left">4</td>
</tr>
<tr class="even">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: character</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">min</th>
<th align="right">max</th>
<th align="right">empty</th>
<th align="right">n_unique</th>
<th align="right">whitespace</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">country</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">3</td>
<td align="right">28</td>
<td align="right">0</td>
<td align="right">193</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">beer_servings</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">106.16</td>
<td align="right">101.14</td>
<td align="right">0</td>
<td align="right">20.0</td>
<td align="right">76.0</td>
<td align="right">188.0</td>
<td align="right">376.0</td>
<td align="left">▇▃▂▂▁</td>
</tr>
<tr class="even">
<td align="left">spirit_servings</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">80.99</td>
<td align="right">88.28</td>
<td align="right">0</td>
<td align="right">4.0</td>
<td align="right">56.0</td>
<td align="right">128.0</td>
<td align="right">438.0</td>
<td align="left">▇▃▂▁▁</td>
</tr>
<tr class="odd">
<td align="left">wine_servings</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">49.45</td>
<td align="right">79.70</td>
<td align="right">0</td>
<td align="right">1.0</td>
<td align="right">8.0</td>
<td align="right">59.0</td>
<td align="right">370.0</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">total_litres_of_pure_alcohol</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">4.72</td>
<td align="right">3.77</td>
<td align="right">0</td>
<td align="right">1.3</td>
<td align="right">4.2</td>
<td align="right">7.2</td>
<td align="right">14.4</td>
<td align="left">▇▃▅▃▁</td>
</tr>
</tbody>
</table>
<p>We can see that there are only 5 variables, out of which 4 are numeric and 1 is character type. Also the <em>n_missing</em> is 0 for all variables, so there are no missing values (NAs) to worry about.</p>
<p>Now, as we skinned the data set, we can proceed to visualization of countries arranged by number of servings. We have three main categories of drinks: beer, wine and spirits. Let’s visualize them one by one:</p>
<div id="beer" class="section level2">
<h2>Beer:</h2>
<pre class="r"><code># get the top 25 countries
beer &lt;- drinks %&gt;% 
  arrange(desc(beer_servings)) %&gt;% 
  head(25)

# create the plot of the top-25 countries using ggplot2
ggplot(beer, aes(y = reorder(country, beer_servings), x = beer_servings)) +
  geom_col() +
  labs(y = &quot;&quot;,
       x = &quot;Servings of Beer&quot;,
       title = &quot;Beer Servings across Countries&quot;,
       caption = &quot;source: fivethirtyeight&quot;) +
  theme_minimal()</code></pre>
<p><img src="/projects/project1/index_files/figure-html/beer_plot-1.png" width="648" style="display: block; margin: auto;" /></p>
</div>
<div id="wine" class="section level2">
<h2>Wine:</h2>
<pre class="r"><code># get the top 25 countries
wine &lt;- drinks %&gt;% 
  arrange(desc(wine_servings)) %&gt;% 
  head(25)

# create the plot of the top-25 countries using ggplot2
ggplot(wine, aes(y = reorder(country, wine_servings), x = wine_servings)) +
  geom_col() +
  labs(y = &quot;&quot;,
       x = &quot;Servings of Wine&quot;,
       title = &quot;Wine Servings across Countries&quot;,
       caption = &quot;source: fivethirtyeight&quot;) +
  theme_minimal()</code></pre>
<p><img src="/projects/project1/index_files/figure-html/wine_plot-1.png" width="648" style="display: block; margin: auto;" /></p>
</div>
<div id="spirits" class="section level2">
<h2>Spirits:</h2>
<pre class="r"><code># get the top 25 countries
spirits &lt;- drinks %&gt;% 
  arrange(desc(spirit_servings)) %&gt;% 
  head(25)

# create the plot of the top-25 countries using ggplot2
ggplot(spirits, aes(y = reorder(country, spirit_servings), x = spirit_servings)) +
  geom_col() +
  labs(y = &quot;&quot;,
       x = &quot;Servings of Spirits&quot;,
       title = &quot;Spirits Servings across Countries&quot;,
       caption = &quot;source: fivethirtyeight&quot;) +
  theme_minimal()</code></pre>
<p><img src="/projects/project1/index_files/figure-html/spirit_plot-1.png" width="648" style="display: block; margin: auto;" /></p>
<blockquote>
<p>Essay:</p>
</blockquote>
<p>The trends for three types of alcohol consumption are similar in the amount distribution while different in the list countries. All top 25 Beer countries have more than 200 servings consumed, while the average for the top 25 Beer and Wine countries are also close to 200 servings. Grenada, the highest spirits-consuming country, has a consumption greater than the highest of Beer (Namibia) and Wine (France). The high consumption of beer by Namibia may relate to its colonial history by German.</p>
<p>From a geographical perspective, spirits’ major consumption is in developing countries, likely due to spirits’ high alcohol content per volume. Two major country groups are ex-soviet countries, which consume Vodka and Caribbean countries, which drink Rum. A detailed look at the types of spirits may reveal differences in country appetites. On the contrary, developed European countries consumed most wine. These countries are both major producers and consumers for wines. Consumption for beer spread across different continent and economic levels, indicating beer as a widely accepted alcohol in the world.</p>
</div>
</div>
<div id="analysis-of-movies--imdb-dataset" class="section level1">
<h1>Analysis of movies- IMDB dataset</h1>
<p>We will look at a subset sample of movies, taken from the <a href="https://www.kaggle.com/carolzhangdc/imdb-5000-movie-dataset">Kaggle IMDB 5000 movie dataset</a>. Firstly, we download it and use <code>glimpse()</code> to get a better understanding of it:</p>
<pre class="r"><code>movies &lt;- read_csv(here::here(&quot;data&quot;, &quot;movies.csv&quot;))
glimpse(movies)</code></pre>
<pre><code>## Rows: 2,961
## Columns: 11
## $ title               &lt;chr&gt; &quot;Avatar&quot;, &quot;Titanic&quot;, &quot;Jurassic World&quot;, &quot;The Ave...
## $ genre               &lt;chr&gt; &quot;Action&quot;, &quot;Drama&quot;, &quot;Action&quot;, &quot;Action&quot;, &quot;Action&quot;...
## $ director            &lt;chr&gt; &quot;James Cameron&quot;, &quot;James Cameron&quot;, &quot;Colin Trevor...
## $ year                &lt;dbl&gt; 2009, 1997, 2015, 2012, 2008, 1999, 1977, 2015,...
## $ duration            &lt;dbl&gt; 178, 194, 124, 173, 152, 136, 125, 141, 164, 93...
## $ gross               &lt;dbl&gt; 7.61e+08, 6.59e+08, 6.52e+08, 6.23e+08, 5.33e+0...
## $ budget              &lt;dbl&gt; 2.37e+08, 2.00e+08, 1.50e+08, 2.20e+08, 1.85e+0...
## $ cast_facebook_likes &lt;dbl&gt; 4834, 45223, 8458, 87697, 57802, 37723, 13485, ...
## $ votes               &lt;dbl&gt; 886204, 793059, 418214, 995415, 1676169, 534658...
## $ reviews             &lt;dbl&gt; 3777, 2843, 1934, 2425, 5312, 3917, 1752, 1752,...
## $ rating              &lt;dbl&gt; 7.9, 7.7, 7.0, 8.1, 9.0, 6.5, 8.7, 7.5, 8.5, 7....</code></pre>
<p>Besides the obvious variables of <code>title</code>, <code>genre</code>, <code>director</code>, <code>year</code>, and <code>duration</code>, the rest of the variables are as follows:</p>
<ul>
<li><code>gross</code> : The gross earnings in the US box office, not adjusted for inflation</li>
<li><code>budget</code>: The movie’s budget</li>
<li><code>cast_facebook_likes</code>: the number of facebook likes cast members received</li>
<li><code>votes</code>: the number of people who voted for (or rated) the movie in IMDB</li>
<li><code>reviews</code>: the number of reviews for that movie</li>
<li><code>rating</code>: IMDB average rating</li>
</ul>
<div id="important-questions-to-understand-the-data-set" class="section level2">
<h2>Important questions to understand the data set:</h2>
<ul>
<li>Are there any missing values (NAs)? Are all entries distinct or are there duplicate entries?</li>
</ul>
<p>We <code>skim()</code> the data to see, whether there are any missing values. Then we look up the distinct lines in the dataset to understand whether there are any duplicating entries:</p>
<pre class="r"><code>skim(movies)</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-1">Table 1: </span>Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">movies</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">2961</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">11</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">character</td>
<td align="left">3</td>
</tr>
<tr class="odd">
<td align="left">numeric</td>
<td align="left">8</td>
</tr>
<tr class="even">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: character</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">min</th>
<th align="right">max</th>
<th align="right">empty</th>
<th align="right">n_unique</th>
<th align="right">whitespace</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">title</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">83</td>
<td align="right">0</td>
<td align="right">2907</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">genre</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">5</td>
<td align="right">11</td>
<td align="right">0</td>
<td align="right">17</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">director</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">3</td>
<td align="right">32</td>
<td align="right">0</td>
<td align="right">1366</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<colgroup>
<col width="13%" />
<col width="6%" />
<col width="9%" />
<col width="6%" />
<col width="6%" />
<col width="4%" />
<col width="6%" />
<col width="6%" />
<col width="6%" />
<col width="6%" />
<col width="28%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">year</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2.00e+03</td>
<td align="right">9.95e+00</td>
<td align="right">1920.0</td>
<td align="right">2.00e+03</td>
<td align="right">2.00e+03</td>
<td align="right">2.01e+03</td>
<td align="right">2.02e+03</td>
<td align="left">▁▁▁▂▇</td>
</tr>
<tr class="even">
<td align="left">duration</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.10e+02</td>
<td align="right">2.22e+01</td>
<td align="right">37.0</td>
<td align="right">9.50e+01</td>
<td align="right">1.06e+02</td>
<td align="right">1.19e+02</td>
<td align="right">3.30e+02</td>
<td align="left">▃▇▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">gross</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">5.81e+07</td>
<td align="right">7.25e+07</td>
<td align="right">703.0</td>
<td align="right">1.23e+07</td>
<td align="right">3.47e+07</td>
<td align="right">7.56e+07</td>
<td align="right">7.61e+08</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">budget</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">4.06e+07</td>
<td align="right">4.37e+07</td>
<td align="right">218.0</td>
<td align="right">1.10e+07</td>
<td align="right">2.60e+07</td>
<td align="right">5.50e+07</td>
<td align="right">3.00e+08</td>
<td align="left">▇▂▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">cast_facebook_likes</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.24e+04</td>
<td align="right">2.05e+04</td>
<td align="right">0.0</td>
<td align="right">2.24e+03</td>
<td align="right">4.60e+03</td>
<td align="right">1.69e+04</td>
<td align="right">6.57e+05</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">votes</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.09e+05</td>
<td align="right">1.58e+05</td>
<td align="right">5.0</td>
<td align="right">1.99e+04</td>
<td align="right">5.57e+04</td>
<td align="right">1.33e+05</td>
<td align="right">1.69e+06</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">reviews</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">5.03e+02</td>
<td align="right">4.94e+02</td>
<td align="right">2.0</td>
<td align="right">1.99e+02</td>
<td align="right">3.64e+02</td>
<td align="right">6.31e+02</td>
<td align="right">5.31e+03</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">rating</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">6.39e+00</td>
<td align="right">1.05e+00</td>
<td align="right">1.6</td>
<td align="right">5.80e+00</td>
<td align="right">6.50e+00</td>
<td align="right">7.10e+00</td>
<td align="right">9.30e+00</td>
<td align="left">▁▁▆▇▁</td>
</tr>
</tbody>
</table>
<pre class="r"><code># using `distinct()` to get unique rows and then we count them
unq_rw &lt;- movies %&gt;% 
  distinct() %&gt;% 
  count()
# conduct a logical test, whether the number of initial rows coincide with the number of distinct rows
unq_rw == count(movies)</code></pre>
<pre><code>##         n
## [1,] TRUE</code></pre>
<pre class="r"><code>## we can also check for the titles of movies and see that there are 54 duplicating movie names in the dataset, but lines are not totally identical
# movies %&gt;% 
#   distinct(title) %&gt;% 
#   count()</code></pre>
<p>As we can see <em>n_missing</em> is zero for all variables, so we have no NAs in the dataset. Moreover, as the logical check <code>unq_rw == count(movies)</code> gives TRUE value, there are no identical rows within the data set.</p>
<ul>
<li>Produce a table with the count of movies by genre, ranked in descending order:</li>
</ul>
<pre class="r"><code>movies %&gt;% 
  group_by(genre) %&gt;% 
  count() %&gt;% 
  arrange(desc(n))</code></pre>
<pre><code>## # A tibble: 17 x 2
## # Groups:   genre [17]
##    genre           n
##    &lt;chr&gt;       &lt;int&gt;
##  1 Comedy        848
##  2 Action        738
##  3 Drama         498
##  4 Adventure     288
##  5 Crime         202
##  6 Biography     135
##  7 Horror        131
##  8 Animation      35
##  9 Fantasy        28
## 10 Documentary    25
## 11 Mystery        16
## 12 Sci-Fi          7
## 13 Family          3
## 14 Musical         2
## 15 Romance         2
## 16 Western         2
## 17 Thriller        1</code></pre>
<ul>
<li>Produce a table with the average gross earning and budget (<code>gross</code> and <code>budget</code>) by genre. For further analysis of returns, we calculate a variable <code>return_on_budget</code> which shows how many $ did a movie make at the box office for each $ of its budget. The output table is ranked by <code>return_on_budget</code> in descending order:</li>
</ul>
<pre class="r"><code>movies %&gt;% 
  group_by(genre) %&gt;% 
  summarise(av_gross = mean(gross), av_budget = mean(budget)) %&gt;% 
  mutate(return_on_budget = av_gross/av_budget) %&gt;% 
  arrange(desc(return_on_budget))</code></pre>
<pre><code>## # A tibble: 17 x 4
##    genre         av_gross av_budget return_on_budget
##    &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;            &lt;dbl&gt;
##  1 Musical      92084000   3189500          28.9    
##  2 Family      149160478. 14833333.         10.1    
##  3 Western      20821884   3465000           6.01   
##  4 Documentary  17353973.  5887852.          2.95   
##  5 Horror       37713738. 13504916.          2.79   
##  6 Fantasy      42408841. 17582143.          2.41   
##  7 Comedy       42630552. 24446319.          1.74   
##  8 Mystery      67533021. 39218750           1.72   
##  9 Animation    98433792. 61701429.          1.60   
## 10 Biography    45201805. 28543696.          1.58   
## 11 Adventure    95794257. 66290069.          1.45   
## 12 Drama        37465371. 26242933.          1.43   
## 13 Crime        37502397. 26596169.          1.41   
## 14 Romance      31264848. 25107500           1.25   
## 15 Action       86583860. 71354888.          1.21   
## 16 Sci-Fi       29788371. 27607143.          1.08   
## 17 Thriller         2468    300000           0.00823</code></pre>
<ul>
<li>Produce a table that shows the top 15 directors who have created the highest gross revenue in the box office. The highest gross revenue is defined as sum of all the revenues for all the films by this director. We also provide the mean, median, and standard deviation per director for better understanding of data:</li>
</ul>
<pre class="r"><code>movies %&gt;% 
  group_by(director) %&gt;% 
  summarise(total = sum(gross),
            mean = mean(gross),
            median = median(gross),
            st_d = StdDev(gross)) %&gt;% 
  arrange(desc(total)) %&gt;% 
  head(15)</code></pre>
<pre><code>## # A tibble: 15 x 5
##    director               total       mean     median   st_d[,1]
##    &lt;chr&gt;                  &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;
##  1 Steven Spielberg  4014061704 174524422. 164435221  101421051.
##  2 Michael Bay       2231242537 171634041. 138396624  127161579.
##  3 Tim Burton        2071275480 129454718.  76519172  108726924.
##  4 Sam Raimi         2014600898 201460090. 234903076  162126632.
##  5 James Cameron     1909725910 318287652. 175562880. 309171337.
##  6 Christopher Nolan 1813227576 226653447  196667606. 187224133.
##  7 George Lucas      1741418480 348283696  380262555  146193880.
##  8 Robert Zemeckis   1619309108 124562239. 100853835   91300279.
##  9 Clint Eastwood    1378321100  72543216.  46700000   75487408.
## 10 Francis Lawrence  1358501971 271700394. 281666058  135437020.
## 11 Ron Howard        1335988092 111332341  101587923   81933761.
## 12 Gore Verbinski    1329600995 189942999. 123207194  154473822.
## 13 Andrew Adamson    1137446920 284361730  279680930. 120895765.
## 14 Shawn Levy        1129750988 102704635.  85463309   65484773.
## 15 Ridley Scott      1128857598  80632686.  47775715   68812285.</code></pre>
<ul>
<li>Finally, we produce a table that describes how ratings are distributed by genre. We show all basic parameters of rating distribution: the mean, min, max, median, SD. Moreover, density graphs that visually shows how ratings are distributed are provided:</li>
</ul>
<pre class="r"><code>movies %&gt;% 
  group_by(genre) %&gt;% 
  summarise(mean_r = mean(rating),
            min_r = min(rating),
            median_r = median(rating),
            max_r = max(rating),
            st_d = StdDev(rating))</code></pre>
<pre><code>## # A tibble: 17 x 6
##    genre       mean_r min_r median_r max_r st_d[,1]
##    &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;
##  1 Action        6.23   2.1     6.3    9      1.03 
##  2 Adventure     6.51   2.3     6.6    8.6    1.09 
##  3 Animation     6.65   4.5     6.9    8      0.968
##  4 Biography     7.11   4.5     7.2    8.9    0.760
##  5 Comedy        6.11   1.9     6.2    8.8    1.02 
##  6 Crime         6.92   4.8     6.9    9.3    0.849
##  7 Documentary   6.66   1.6     7.4    8.5    1.77 
##  8 Drama         6.73   2.1     6.8    8.8    0.917
##  9 Family        6.5    5.7     5.9    7.9    1.22 
## 10 Fantasy       6.15   4.3     6.45   7.9    0.959
## 11 Horror        5.83   3.6     5.9    8.5    1.01 
## 12 Musical       6.75   6.3     6.75   7.2    0.636
## 13 Mystery       6.86   4.6     6.9    8.5    0.882
## 14 Romance       6.65   6.2     6.65   7.1    0.636
## 15 Sci-Fi        6.66   5       6.4    8.2    1.09 
## 16 Thriller      4.8    4.8     4.8    4.8   NA    
## 17 Western       5.70   4.1     5.70   7.3    2.26</code></pre>
<pre class="r"><code>ggplot(movies, aes(rating)) +
  geom_density() +
  facet_wrap(~genre, scales = &quot;free_y&quot;) +
  labs(x = &quot;IMDB Rating&quot;,
       y = &quot;&quot;)</code></pre>
<p><img src="/projects/project1/index_files/figure-html/unnamed-chunk-5-1.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code># ggplot(movies, aes(rating)) +
#   geom_histogram() +
#   facet_wrap(~genre, scales = &quot;free_y&quot;)</code></pre>
<ul>
<li>Note that <em>Thriller</em> category has only 1 observation, which leads to an absent density graph.</li>
</ul>
</div>
<div id="graphical-analysis-of-data-set-using-ggplot" class="section level2">
<h2>Graphical Analysis of Data Set (using <code>ggplot</code>)</h2>
<ul>
<li>To examine the relationship between <code>gross</code> and <code>cast_facebook_likes</code> we produce a scatterplot. Such visualization might help to understand whether the number of facebook likes that the cast has received is likely to be a good predictor of how much money a movie will make at the box office:</li>
</ul>
<pre class="r"><code># On X-axis we put Facebook Likes (as it is an explanatory variable in this case)
# On Y-axis we put Gross Earnings in box office in the US (as a dependent variable)
ggplot(movies, aes(x = cast_facebook_likes, y = gross)) +
  geom_point() +
  geom_smooth(method = &quot;lm&quot;) +
  scale_x_log10() +
  scale_y_log10() +
  labs(x = &quot;Cast Likes on Facebook&quot;,
       y = &quot;US Box Office&quot;)</code></pre>
<p><img src="/projects/project1/index_files/figure-html/gross_on_fblikes-1.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Also we calculate correlation to see the strength of linear connection
cor(movies$cast_facebook_likes, movies$gross)</code></pre>
<pre><code>## [1] 0.213</code></pre>
<p>Facebook likes is quite poor predictor for the box office in the US, as correlation is weak. The facebook likes variable is clustered around a small area, while gross earnings are more scattered. This suggests that the linear model might be unstable here and the explanatory power will be quite low.</p>
<ul>
<li>Next we examine the relationship between <code>gross</code> and <code>budget</code>. We again produce a scatterplot to see whether budget is likely to be a good predictor of how much money a movie will make at the box office:</li>
</ul>
<pre class="r"><code># On X-axis we put Budget (as it is an explanatory variable in this case)
# On Y-axis we put Gross Earnings in box office in the US (as a dependent variable)
ggplot(movies, aes(x = budget, y = gross)) +
   geom_point() +
  geom_smooth(method = &quot;lm&quot;) +
  scale_x_log10() +
  scale_y_log10() +
  labs(x = &quot;Movie Budget&quot;,
       y = &quot;US Box Office&quot;)</code></pre>
<p><img src="/projects/project1/index_files/figure-html/gross_on_budget-1.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Also we calculate correlation
cor(movies$budget, movies$gross)</code></pre>
<pre><code>## [1] 0.641</code></pre>
<p>Budget is a moderate predictor to the box office in the US, as the correlation is quite high (above 0.5). We can also highlight that for high budget movies it is a better predictor, as they are more concentrated around the best fit line than the low budget movies.</p>
<ul>
<li>By producing another scatterplot we examine the relationship between <code>gross</code> and <code>rating</code>. We facet by <code>genre</code> to see whether IMDB ratings are likely to be a good predictor of how much money a movie will make at the box office in each <code>genre</code> type:</li>
</ul>
<pre class="r"><code>ggplot(movies, aes(x = rating, y = gross)) +
  geom_point() +
  geom_smooth(method = &quot;lm&quot;) +
  scale_y_log10() +
  facet_wrap(~genre) +
  labs(x = &quot;IMDB Rating&quot;,
       y = &quot;US Box Office&quot;)</code></pre>
<p><img src="/projects/project1/index_files/figure-html/gross_on_rating-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>The dataset has an initial problem for this kind of analysis in that some genres – thrillers, musicals, westerns – have so few datapoint that any analysis bears no fruit. That being said, those datasets with a more full picture show a generally quite robust correlation between rating and movie gross. This is especially true for Action and Adventure movies, which have the most clear trend, while, for example, comedy movies show more significant drops in gross revenue.
Of course, looking at IMDb ratings comes with the caveat that ratings are typically most common in the years after a movie has been released. Movies that grossed highly during their release, while already tending to be popular, are likely to be watched more, and may therefore experience a rise in ratings. Similarly, movies may become cult classics, and through this achieve high ratings later on, even if they had an unsuccessful economic performance.</p>
</div>
</div>
<div id="returns-of-financial-stocks" class="section level1">
<h1>Returns of financial stocks</h1>
<p>We will use the <code>tidyquant</code> package to download historical data of stock prices, calculate returns, and examine the distribution of returns.
We must first identify which stocks we want to download data for, and for this we must know their ticker symbol. The file <code>nyse.csv</code> contains 508 stocks listed on the NYSE, their ticker <code>symbol</code>, <code>name</code>, the IPO (Initial Public Offering) year, and the sector and industry the company is in.</p>
<pre class="r"><code>nyse &lt;- read_csv(here::here(&quot;data&quot;,&quot;nyse.csv&quot;))</code></pre>
<p>Based on this dataset, create a table and a bar plot that shows the number of companies per sector, in descending order:</p>
<pre class="r"><code>sector_count &lt;- nyse %&gt;%
  group_by(sector) %&gt;% 
  count() %&gt;% 
  arrange(desc(n))
# call a table to reproduce it
sector_count</code></pre>
<pre><code>## # A tibble: 12 x 2
## # Groups:   sector [12]
##    sector                    n
##    &lt;chr&gt;                 &lt;int&gt;
##  1 Finance                  97
##  2 Consumer Services        79
##  3 Public Utilities         60
##  4 Capital Goods            45
##  5 Health Care              45
##  6 Energy                   42
##  7 Technology               40
##  8 Basic Industries         39
##  9 Consumer Non-Durables    31
## 10 Miscellaneous            12
## 11 Transportation           10
## 12 Consumer Durables         8</code></pre>
<pre class="r"><code>ggplot(sector_count, aes(x = n, y = reorder(sector, n))) +
  geom_col() +
  labs(x = &quot;&quot;,
       y = &quot;Sector&quot;)</code></pre>
<p><img src="/projects/project1/index_files/figure-html/companies_per_sector-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>Next, let’s choose the <a href="https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average">Dow Jones Industrial Average (DJIA)</a> stocks and their ticker symbols and download some data. Besides the thirty stocks that make up the DJIA, we will also add <code>SPY</code> which is an SP500 ETF (Exchange Traded Fund).</p>
<pre class="r"><code>djia_url &lt;- &quot;https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average&quot;

#get tables that exist on URL
tables &lt;- djia_url %&gt;% 
  read_html() %&gt;% 
  html_nodes(css=&quot;table&quot;)

# parse HTML tables into a dataframe called djia. 
# Use purr::map() to create a list of all tables in URL
djia &lt;- map(tables, . %&gt;% 
               html_table(fill=TRUE)%&gt;% 
               clean_names())

# constituents
table1 &lt;- djia[[2]] %&gt;% # the second table on the page contains the ticker symbols
  mutate(date_added = ymd(date_added),
        
         # if a stock is listed on NYSE, its symbol is, e.g., NYSE: MMM
         # We will get prices from yahoo finance which requires just the ticker
         
         # if symbol contains &quot;NYSE*&quot;, the * being a wildcard
         # then we jsut drop the first 6 characters in that string
         ticker = ifelse(str_detect(symbol, &quot;NYSE*&quot;),
                          str_sub(symbol,7,11),
                          symbol)
         )

# we need a vector of strings with just the 30 tickers + SPY
tickers &lt;- table1 %&gt;% 
  select(ticker) %&gt;% 
  pull() %&gt;% # pull() gets them as a sting of characters
  c(&quot;SPY&quot;) # and lets us add SPY, the SP500 ETF</code></pre>
<p>After downloading and clearing the data a little bit, we should <code>glimpse</code> at it to understand the structure of the final data set:</p>
<pre class="r"><code># Notice the cache=TRUE argument in the chunk options. Because getting data is time consuming, # cache=TRUE means that once it downloads data, the chunk will not run again next time you knit your Rmd

myStocks &lt;- tickers %&gt;% 
  tq_get(get  = &quot;stock.prices&quot;,
         from = &quot;2000-01-01&quot;,
         to   = &quot;2020-08-31&quot;) %&gt;%
  group_by(symbol) 

glimpse(myStocks) # examine the structure of the resulting data frame</code></pre>
<pre><code>## Rows: 153,121
## Columns: 8
## Groups: symbol [31]
## $ symbol   &lt;chr&gt; &quot;MMM&quot;, &quot;MMM&quot;, &quot;MMM&quot;, &quot;MMM&quot;, &quot;MMM&quot;, &quot;MMM&quot;, &quot;MMM&quot;, &quot;MMM&quot;, &quot;M...
## $ date     &lt;date&gt; 2000-01-03, 2000-01-04, 2000-01-05, 2000-01-06, 2000-01-0...
## $ open     &lt;dbl&gt; 48.0, 46.4, 45.6, 47.2, 50.6, 50.2, 50.4, 51.0, 50.7, 50.4...
## $ high     &lt;dbl&gt; 48.2, 47.4, 48.1, 51.2, 51.9, 51.8, 51.2, 51.8, 50.9, 50.5...
## $ low      &lt;dbl&gt; 47.0, 45.3, 45.6, 47.2, 50.0, 50.0, 50.2, 50.4, 50.2, 49.5...
## $ close    &lt;dbl&gt; 47.2, 45.3, 46.6, 50.4, 51.4, 51.1, 50.2, 50.4, 50.4, 49.7...
## $ volume   &lt;dbl&gt; 2173400, 2713800, 3699400, 5975800, 4101200, 3863800, 2357...
## $ adjusted &lt;dbl&gt; 28.1, 26.9, 27.7, 30.0, 30.5, 30.4, 29.9, 30.0, 30.0, 29.5...</code></pre>
<p>Financial performance analysis depend on returns; If I buy a stock today for 100 and I sell it tomorrow for 101.75, my one-day return, assuming no transaction costs, is 1.75%. So given the adjusted closing prices, our first step is to calculate daily and monthly returns:</p>
<pre class="r"><code>#calculate daily returns
myStocks_returns_daily &lt;- myStocks %&gt;%
  tq_transmute(select     = adjusted, 
               mutate_fun = periodReturn, 
               period     = &quot;daily&quot;, 
               type       = &quot;log&quot;,
               col_rename = &quot;daily_returns&quot;,
               cols = c(nested.col))  

#calculate monthly  returns
myStocks_returns_monthly &lt;- myStocks %&gt;%
  tq_transmute(select     = adjusted, 
               mutate_fun = periodReturn, 
               period     = &quot;monthly&quot;, 
               type       = &quot;arithmetic&quot;,
               col_rename = &quot;monthly_returns&quot;,
               cols = c(nested.col)) 

#calculate yearly returns
myStocks_returns_annual &lt;- myStocks %&gt;%
  group_by(symbol) %&gt;%
  tq_transmute(select     = adjusted, 
               mutate_fun = periodReturn, 
               period     = &quot;yearly&quot;, 
               type       = &quot;arithmetic&quot;,
               col_rename = &quot;yearly_returns&quot;,
               cols = c(nested.col))</code></pre>
<p>Now having all the returns calculated, we create a dataframe and assign it to a new object, where we summarise monthly returns since 2017-01-01 for each of the stocks and <code>SPY</code>; min, max, median, mean, SD.</p>
<pre class="r"><code>st_data &lt;- myStocks_returns_monthly %&gt;% 
  filter(date &gt; &quot;2017-01-01&quot;) %&gt;% 
  group_by(symbol) %&gt;%
  summarise(min_r = min(monthly_returns), max_r = max(monthly_returns), median_r = median(monthly_returns),
            mean_r = mean(monthly_returns), sd_r = STDEV(monthly_returns))</code></pre>
<p>Next step is to plot a density plot, using <code>geom_density()</code>, for each of the stocks:</p>
<pre class="r"><code>ggplot(myStocks_returns_monthly, aes(monthly_returns)) +
  geom_density() +
  facet_wrap(~symbol) +
  labs(x = &quot;Monthly Returns&quot;,
       y = &quot;&quot;)</code></pre>
<p><img src="/projects/project1/index_files/figure-html/density_monthly_returns-1.png" width="648" style="display: block; margin: auto;" /></p>
<blockquote>
<p>Inference:</p>
</blockquote>
<p>The riskiest stock should have the highest variance and graphically it implies lowest peak with fat tails. Moreover, skewness of the returns should be taken into consideration. According to these criteria <strong>DOW</strong> (chemical company stock) seems to be the riskiest stock out of the chosen sample.
The least risky asset is <strong>SPY</strong>, which is expected as it is a diversified index (with low idiosyncratic risk). If we are looking at the stocks only than <strong>JNJ</strong> and <strong>PG</strong> look as the least risky assets.</p>
<p>Finally, we produce a plot that shows the expected monthly return (mean) of a stock on the Y axis and the risk (standard deviation) in the X-axis. We use <code>ggrepel::geom_text_repel()</code> to label each stock with its ticker symbol:</p>
<pre class="r"><code>ggplot(st_data, aes(x = sd_r, y = mean_r)) +
  geom_point() +
  geom_text_repel(label = st_data$symbol) +
  labs(x = &quot;Standard Deviation&quot;,
       y = &quot;Mean Returns&quot;)</code></pre>
<p><img src="/projects/project1/index_files/figure-html/risk_return_plot-1.png" width="648" style="display: block; margin: auto;" /></p>
<blockquote>
<p>Inference:</p>
</blockquote>
<p>Most stocks are clustered around a mean return of 1%-2% and a standard deviation of 5%-7%. We can see that <strong>DOW</strong> and <strong>BA</strong> have a higher standard deviation than other stocks implying a higher level of risk. While the mean return is similar to most other stocks, which suggests a worse risk-return trade-off.
On the other hand, <strong>MSFT</strong>, <strong>AAPL</strong> and <strong>CRM</strong> have a similar standard deviation to most stocks while having a much higher mean return making them a more preferable choice.
There are also 2 stocks (<strong>CVX</strong> and <strong>WBA</strong>, especially) for which the mean returns are below zero, while the risk profile as represented by standard deviation is similar to the main cluster of stocks.</p>
</div>
<div id="on-your-own-ibm-hr-analytics" class="section level1">
<h1>On your own: IBM HR Analytics</h1>
<p>For this task, we will analyse a data set on Human Resoruce Analytics. The <a href="https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset">IBM HR Analytics Employee Attrition &amp; Performance data set</a> is a fictional data set created by IBM data scientists. Among other things, the data set includes employees’ income, their distance from work, their position in the company, their level of education, etc. A full description can be found on the website.</p>
<p>First let us load the data and glimpse it:</p>
<pre class="r"><code>hr_dataset &lt;- read_csv(here::here(&quot;data&quot;, &quot;datasets_1067_1925_WA_Fn-UseC_-HR-Employee-Attrition.csv&quot;))
glimpse(hr_dataset)</code></pre>
<pre><code>## Rows: 1,470
## Columns: 35
## $ Age                      &lt;dbl&gt; 41, 49, 37, 33, 27, 32, 59, 30, 38, 36, 35...
## $ Attrition                &lt;chr&gt; &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;...
## $ BusinessTravel           &lt;chr&gt; &quot;Travel_Rarely&quot;, &quot;Travel_Frequently&quot;, &quot;Tra...
## $ DailyRate                &lt;dbl&gt; 1102, 279, 1373, 1392, 591, 1005, 1324, 13...
## $ Department               &lt;chr&gt; &quot;Sales&quot;, &quot;Research &amp; Development&quot;, &quot;Resear...
## $ DistanceFromHome         &lt;dbl&gt; 1, 8, 2, 3, 2, 2, 3, 24, 23, 27, 16, 15, 2...
## $ Education                &lt;dbl&gt; 2, 1, 2, 4, 1, 2, 3, 1, 3, 3, 3, 2, 1, 2, ...
## $ EducationField           &lt;chr&gt; &quot;Life Sciences&quot;, &quot;Life Sciences&quot;, &quot;Other&quot;,...
## $ EmployeeCount            &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
## $ EmployeeNumber           &lt;dbl&gt; 1, 2, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, ...
## $ EnvironmentSatisfaction  &lt;dbl&gt; 2, 3, 4, 4, 1, 4, 3, 4, 4, 3, 1, 4, 1, 2, ...
## $ Gender                   &lt;chr&gt; &quot;Female&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Female&quot;, &quot;Male&quot;...
## $ HourlyRate               &lt;dbl&gt; 94, 61, 92, 56, 40, 79, 81, 67, 44, 94, 84...
## $ JobInvolvement           &lt;dbl&gt; 3, 2, 2, 3, 3, 3, 4, 3, 2, 3, 4, 2, 3, 3, ...
## $ JobLevel                 &lt;dbl&gt; 2, 2, 1, 1, 1, 1, 1, 1, 3, 2, 1, 2, 1, 1, ...
## $ JobRole                  &lt;chr&gt; &quot;Sales Executive&quot;, &quot;Research Scientist&quot;, &quot;...
## $ JobSatisfaction          &lt;dbl&gt; 4, 2, 3, 3, 2, 4, 1, 3, 3, 3, 2, 3, 3, 4, ...
## $ MaritalStatus            &lt;chr&gt; &quot;Single&quot;, &quot;Married&quot;, &quot;Single&quot;, &quot;Married&quot;, ...
## $ MonthlyIncome            &lt;dbl&gt; 5993, 5130, 2090, 2909, 3468, 3068, 2670, ...
## $ MonthlyRate              &lt;dbl&gt; 19479, 24907, 2396, 23159, 16632, 11864, 9...
## $ NumCompaniesWorked       &lt;dbl&gt; 8, 1, 6, 1, 9, 0, 4, 1, 0, 6, 0, 0, 1, 0, ...
## $ Over18                   &lt;chr&gt; &quot;Y&quot;, &quot;Y&quot;, &quot;Y&quot;, &quot;Y&quot;, &quot;Y&quot;, &quot;Y&quot;, &quot;Y&quot;, &quot;Y&quot;, &quot;Y...
## $ OverTime                 &lt;chr&gt; &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Ye...
## $ PercentSalaryHike        &lt;dbl&gt; 11, 23, 15, 11, 12, 13, 20, 22, 21, 13, 13...
## $ PerformanceRating        &lt;dbl&gt; 3, 4, 3, 3, 3, 3, 4, 4, 4, 3, 3, 3, 3, 3, ...
## $ RelationshipSatisfaction &lt;dbl&gt; 1, 4, 2, 3, 4, 3, 1, 2, 2, 2, 3, 4, 4, 3, ...
## $ StandardHours            &lt;dbl&gt; 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80...
## $ StockOptionLevel         &lt;dbl&gt; 0, 1, 0, 0, 1, 0, 3, 1, 0, 2, 1, 0, 1, 1, ...
## $ TotalWorkingYears        &lt;dbl&gt; 8, 10, 7, 8, 6, 8, 12, 1, 10, 17, 6, 10, 5...
## $ TrainingTimesLastYear    &lt;dbl&gt; 0, 3, 3, 3, 3, 2, 3, 2, 2, 3, 5, 3, 1, 2, ...
## $ WorkLifeBalance          &lt;dbl&gt; 1, 3, 3, 3, 3, 2, 2, 3, 3, 2, 3, 3, 2, 3, ...
## $ YearsAtCompany           &lt;dbl&gt; 6, 10, 0, 8, 2, 7, 1, 1, 9, 7, 5, 9, 5, 2,...
## $ YearsInCurrentRole       &lt;dbl&gt; 4, 7, 0, 7, 2, 7, 0, 0, 7, 7, 4, 5, 2, 2, ...
## $ YearsSinceLastPromotion  &lt;dbl&gt; 0, 1, 0, 3, 2, 3, 0, 0, 1, 7, 0, 0, 4, 1, ...
## $ YearsWithCurrManager     &lt;dbl&gt; 5, 7, 0, 0, 2, 6, 0, 0, 8, 7, 3, 8, 3, 2, ...</code></pre>
<p>The data set is cleaned, as variable names are in capital letters, some variables are not really necessary, and some variables, e.g., <code>education</code> are given as a number rather than a more useful description:</p>
<pre class="r"><code>hr_cleaned &lt;- hr_dataset %&gt;% 
  clean_names() %&gt;% 
  mutate(
    education = case_when(
      education == 1 ~ &quot;Below College&quot;,
      education == 2 ~ &quot;College&quot;,
      education == 3 ~ &quot;Bachelor&quot;,
      education == 4 ~ &quot;Master&quot;,
      education == 5 ~ &quot;Doctor&quot;
    ),
    environment_satisfaction = case_when(
      environment_satisfaction == 1 ~ &quot;Low&quot;,
      environment_satisfaction == 2 ~ &quot;Medium&quot;,
      environment_satisfaction == 3 ~ &quot;High&quot;,
      environment_satisfaction == 4 ~ &quot;Very High&quot;
    ),
    job_satisfaction = case_when(
      job_satisfaction == 1 ~ &quot;Low&quot;,
      job_satisfaction == 2 ~ &quot;Medium&quot;,
      job_satisfaction == 3 ~ &quot;High&quot;,
      job_satisfaction == 4 ~ &quot;Very High&quot;
    ),
    performance_rating = case_when(
      performance_rating == 1 ~ &quot;Low&quot;,
      performance_rating == 2 ~ &quot;Good&quot;,
      performance_rating == 3 ~ &quot;Excellent&quot;,
      performance_rating == 4 ~ &quot;Outstanding&quot;
    ),
    work_life_balance = case_when(
      work_life_balance == 1 ~ &quot;Bad&quot;,
      work_life_balance == 2 ~ &quot;Good&quot;,
      work_life_balance == 3 ~ &quot;Better&quot;,
      work_life_balance == 4 ~ &quot;Best&quot;
    )
  ) %&gt;% 
  select(age, attrition, daily_rate, department,
         distance_from_home, education,
         gender, job_role,environment_satisfaction,
         job_satisfaction, marital_status,
         monthly_income, num_companies_worked, percent_salary_hike,
         performance_rating, total_working_years,
         work_life_balance, years_at_company,
         years_since_last_promotion)

# glimpse the data to understand the structure
glimpse(hr_cleaned)</code></pre>
<pre><code>## Rows: 1,470
## Columns: 19
## $ age                        &lt;dbl&gt; 41, 49, 37, 33, 27, 32, 59, 30, 38, 36, ...
## $ attrition                  &lt;chr&gt; &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;N...
## $ daily_rate                 &lt;dbl&gt; 1102, 279, 1373, 1392, 591, 1005, 1324, ...
## $ department                 &lt;chr&gt; &quot;Sales&quot;, &quot;Research &amp; Development&quot;, &quot;Rese...
## $ distance_from_home         &lt;dbl&gt; 1, 8, 2, 3, 2, 2, 3, 24, 23, 27, 16, 15,...
## $ education                  &lt;chr&gt; &quot;College&quot;, &quot;Below College&quot;, &quot;College&quot;, &quot;...
## $ gender                     &lt;chr&gt; &quot;Female&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Female&quot;, &quot;Mal...
## $ job_role                   &lt;chr&gt; &quot;Sales Executive&quot;, &quot;Research Scientist&quot;,...
## $ environment_satisfaction   &lt;chr&gt; &quot;Medium&quot;, &quot;High&quot;, &quot;Very High&quot;, &quot;Very Hig...
## $ job_satisfaction           &lt;chr&gt; &quot;Very High&quot;, &quot;Medium&quot;, &quot;High&quot;, &quot;High&quot;, &quot;...
## $ marital_status             &lt;chr&gt; &quot;Single&quot;, &quot;Married&quot;, &quot;Single&quot;, &quot;Married&quot;...
## $ monthly_income             &lt;dbl&gt; 5993, 5130, 2090, 2909, 3468, 3068, 2670...
## $ num_companies_worked       &lt;dbl&gt; 8, 1, 6, 1, 9, 0, 4, 1, 0, 6, 0, 0, 1, 0...
## $ percent_salary_hike        &lt;dbl&gt; 11, 23, 15, 11, 12, 13, 20, 22, 21, 13, ...
## $ performance_rating         &lt;chr&gt; &quot;Excellent&quot;, &quot;Outstanding&quot;, &quot;Excellent&quot;,...
## $ total_working_years        &lt;dbl&gt; 8, 10, 7, 8, 6, 8, 12, 1, 10, 17, 6, 10,...
## $ work_life_balance          &lt;chr&gt; &quot;Bad&quot;, &quot;Better&quot;, &quot;Better&quot;, &quot;Better&quot;, &quot;Be...
## $ years_at_company           &lt;dbl&gt; 6, 10, 0, 8, 2, 7, 1, 1, 9, 7, 5, 9, 5, ...
## $ years_since_last_promotion &lt;dbl&gt; 0, 1, 0, 3, 2, 3, 0, 0, 1, 7, 0, 0, 4, 1...</code></pre>
<p>Having understood the structure of the dataset, we can analyse it from different prospectives and summarize out thoughts in a short essay:</p>
<ul>
<li>How often do people leave the company (<code>attrition</code>): 0.161 or 16.1%</li>
</ul>
<pre class="r"><code>leave_comp &lt;- hr_cleaned %&gt;% 
  filter(attrition == &quot;Yes&quot;) %&gt;% 
  count()

## We can do filtering using basic R syntax
# leave_comp &lt;- count(hr_cleaned[hr_cleaned$attrition == &quot;Yes&quot;,])

leave_share &lt;- leave_comp/count(hr_cleaned)*100
cat(leave_share[1,1], &quot;%&quot;)</code></pre>
<pre><code>## 16.1 %</code></pre>
<ul>
<li>How are <code>age</code>, <code>years_at_company</code>, <code>monthly_income</code> and <code>years_since_last_promotion</code> distributed? Can you roughly guess which of these variables is closer to Normal just by looking at summary statistics?</li>
</ul>
<pre class="r"><code># In this chunk we use mainly basic R code, as `summary` function gives all the values needed to see the distribution at once
# then we only have to add standard deviation and call the list to see the output

age_stat &lt;- summary(hr_cleaned$age)
age_stat &lt;- c(age_stat, Sd = STDEV(hr_cleaned$age))
print(&quot;Age distribution&quot;)</code></pre>
<pre><code>## [1] &quot;Age distribution&quot;</code></pre>
<pre class="r"><code>age_stat</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.      Sd 
##   18.00   30.00   36.00   36.92   43.00   60.00    9.14</code></pre>
<pre class="r"><code>ggplot(hr_cleaned, aes(age)) +
  geom_density() +
  labs(x = &quot;Age&quot;,
       y = &quot;&quot;)</code></pre>
<p><img src="/projects/project1/index_files/figure-html/unnamed-chunk-9-1.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code>yac_stat &lt;- summary(hr_cleaned$years_at_company)
yac_stat &lt;- c(yac_stat, Sd = STDEV(hr_cleaned$years_at_company))
print(&quot;Years at company distribution&quot;)</code></pre>
<pre><code>## [1] &quot;Years at company distribution&quot;</code></pre>
<pre class="r"><code>yac_stat</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.      Sd 
##    0.00    3.00    5.00    7.01    9.00   40.00    6.13</code></pre>
<pre class="r"><code>ggplot(hr_cleaned, aes(years_at_company)) +
  geom_density() +
  labs(x = &quot;Years at Company&quot;,
       y = &quot;&quot;)</code></pre>
<p><img src="/projects/project1/index_files/figure-html/unnamed-chunk-9-2.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code>mi_stat &lt;- summary(hr_cleaned$monthly_income)
mi_stat &lt;- c(mi_stat, Sd = STDEV(hr_cleaned$monthly_income))
print(&quot;Monthly Income distribution&quot;)</code></pre>
<pre><code>## [1] &quot;Monthly Income distribution&quot;</code></pre>
<pre class="r"><code>mi_stat</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.      Sd 
##    1009    2911    4919    6503    8379   19999    4708</code></pre>
<pre class="r"><code>ggplot(hr_cleaned, aes(monthly_income)) +
  geom_density() +
  labs(x = &quot;Monthly Income&quot;,
       y = &quot;&quot;)</code></pre>
<p><img src="/projects/project1/index_files/figure-html/unnamed-chunk-9-3.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code>yslp_stat &lt;- summary(hr_cleaned$years_since_last_promotion)
yslp_stat &lt;- c(yslp_stat, Sd = STDEV(hr_cleaned$years_since_last_promotion))
print(&quot;Years since last promotion distribution&quot;)</code></pre>
<pre><code>## [1] &quot;Years since last promotion distribution&quot;</code></pre>
<pre class="r"><code>yslp_stat</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.      Sd 
##    0.00    0.00    1.00    2.19    3.00   15.00    3.22</code></pre>
<pre class="r"><code>ggplot(hr_cleaned, aes(years_since_last_promotion)) +
  geom_density() +
  labs(x = &quot;Years since last promotion&quot;,
       y = &quot;&quot;)</code></pre>
<p><img src="/projects/project1/index_files/figure-html/unnamed-chunk-9-4.png" width="648" style="display: block; margin: auto;" /></p>
<ul>
<li>How are <code>job_satisfaction</code> and <code>work_life_balance</code> distributed? We express categories as % of total:</li>
</ul>
<pre class="r"><code># Get the total number of workers
workrs_num &lt;- length(hr_cleaned$job_satisfaction)

satisf &lt;- hr_cleaned %&gt;% 
  group_by(job_satisfaction) %&gt;% 
  count() %&gt;% 
  arrange(n) %&gt;% 
  mutate(share = n/workrs_num*100)

# We also sort the table from the lowest satisfaction to highest
satisf$job_satisfaction &lt;- factor(satisf$job_satisfaction, levels = c(&quot;Low&quot;, &quot;Medium&quot;, &quot;High&quot;, &quot;Very High&quot;))
satisf &lt;- satisf[order(satisf$job_satisfaction), ]
satisf</code></pre>
<pre><code>## # A tibble: 4 x 3
## # Groups:   job_satisfaction [4]
##   job_satisfaction     n share
##   &lt;fct&gt;            &lt;int&gt; &lt;dbl&gt;
## 1 Low                289  19.7
## 2 Medium             280  19.0
## 3 High               442  30.1
## 4 Very High          459  31.2</code></pre>
<pre class="r"><code>wl_balance &lt;- hr_cleaned %&gt;% 
  group_by(work_life_balance) %&gt;% 
  count() %&gt;% 
  mutate(share = n/workrs_num*100)

# We also sort the table from the worst to the best work-life balance
wl_balance$work_life_balance &lt;- factor(wl_balance$work_life_balance, levels = c(&quot;Bad&quot;, &quot;Good&quot;, &quot;Better&quot;, &quot;Best&quot;))
wl_balance &lt;- wl_balance[order(wl_balance$work_life_balance), ]
wl_balance</code></pre>
<pre><code>## # A tibble: 4 x 3
## # Groups:   work_life_balance [4]
##   work_life_balance     n share
##   &lt;fct&gt;             &lt;int&gt; &lt;dbl&gt;
## 1 Bad                  80  5.44
## 2 Good                344 23.4 
## 3 Better              893 60.7 
## 4 Best                153 10.4</code></pre>
<ul>
<li>Is there any relationship between monthly income and education? Monthly income and gender?</li>
</ul>
<pre class="r"><code>hr_cleaned$education &lt;- factor(hr_cleaned$education, levels = c(&quot;Below College&quot;, &quot;College&quot;, &quot;Bachelor&quot;, &quot;Master&quot;, &quot;Doctor&quot;))
hr_cleaned_srt &lt;- hr_cleaned[order(hr_cleaned$education), ]
hr_cleaned_srt %&gt;% 
  group_by(education) %&gt;% 
  summarise(min_pay = min(monthly_income), median_pay = median(monthly_income), max_pay = max(monthly_income),
            mean_pay = mean(monthly_income), sd_pay = STDEV(monthly_income))</code></pre>
<pre><code>## # A tibble: 5 x 6
##   education     min_pay median_pay max_pay mean_pay sd_pay
##   &lt;fct&gt;           &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;
## 1 Below College    1009      3849    19973    5641.  4485.
## 2 College          1051      4892.   19613    6227.  4525.
## 3 Bachelor         1081      4762    19926    6517.  4817.
## 4 Master           1359      5342.   19999    6832.  4657.
## 5 Doctor           2127      6203    19586    8278.  5061.</code></pre>
<pre class="r"><code>hr_cleaned %&gt;% 
  group_by(gender) %&gt;% 
  summarise(min_pay = min(monthly_income), median_pay = median(monthly_income), max_pay = max(monthly_income),
            mean_pay = mean(monthly_income), sd_pay = STDEV(monthly_income))</code></pre>
<pre><code>## # A tibble: 2 x 6
##   gender min_pay median_pay max_pay mean_pay sd_pay
##   &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;
## 1 Female    1129      5082.   19973    6687.  4696.
## 2 Male      1009      4838.   19999    6381.  4715.</code></pre>
<pre class="r"><code>gndr_pay &lt;- hr_cleaned %&gt;% 
  group_by(gender) %&gt;% 
  summarise(med_pay = median(monthly_income))
ggplot(gndr_pay, aes(x = gender, y = med_pay)) +
  geom_col() +
  labs(x = &quot;Gender&quot;,
       y = &quot;Median Income&quot;)</code></pre>
<p><img src="/projects/project1/index_files/figure-html/unnamed-chunk-11-1.png" width="648" style="display: block; margin: auto;" /></p>
<ul>
<li>Plot a boxplot of income vs job role. Make sure the highest-paid job roles appear first</li>
</ul>
<pre class="r"><code># we compare payment for job roles on median basis

job_pays &lt;- hr_cleaned %&gt;% 
  group_by(job_role) %&gt;% 
  summarise(med_pay = median(monthly_income)) %&gt;% 
  arrange(desc(med_pay))
job_pays</code></pre>
<pre><code>## # A tibble: 9 x 2
##   job_role                  med_pay
##   &lt;chr&gt;                       &lt;dbl&gt;
## 1 Manager                    17454.
## 2 Research Director          16510 
## 3 Healthcare Representative   6811 
## 4 Manufacturing Director      6447 
## 5 Sales Executive             6231 
## 6 Human Resources             3093 
## 7 Research Scientist          2888.
## 8 Laboratory Technician       2886 
## 9 Sales Representative        2579</code></pre>
<pre class="r"><code>ggplot(hr_cleaned, aes(x = monthly_income, y = reorder(job_role, monthly_income, FUN = median))) +
  geom_boxplot() +
  labs(x = &quot;Monthly Income&quot;,
       y = &quot;Job Role&quot;) +
  theme(axis.text.x = element_text(size = 8, angle = 45, vjust = 0.9, hjust = 0.8))</code></pre>
<p><img src="/projects/project1/index_files/figure-html/unnamed-chunk-12-1.png" width="648" style="display: block; margin: auto;" /></p>
<ul>
<li>Calculate and plot a bar chart of the mean (or median?) income by education level.</li>
</ul>
<pre class="r"><code># we consider median to be a more robust measure for analysis, so median income is used

med_ed &lt;- hr_cleaned %&gt;% 
  group_by(education) %&gt;% 
  summarise(med_inc = median(monthly_income))

ggplot(med_ed, aes(x = education, y = med_inc)) +
  geom_col() +
  labs(x = &quot;Education&quot;,
       y = &quot;Median Income&quot;)</code></pre>
<p><img src="/projects/project1/index_files/figure-html/unnamed-chunk-13-1.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code># # mean analysis is provided below as an alternative option
# mean_ed &lt;- hr_cleaned %&gt;% 
#   group_by(education) %&gt;% 
#   summarise(mean_inc = mean(monthly_income))
# 
# ggplot(mean_ed, aes(x = education, y = mean_inc)) +
#   geom_col()</code></pre>
<ul>
<li>Plot the distribution of income by education level. Use a facet_wrap and a theme from <code>ggthemes</code></li>
</ul>
<pre class="r"><code>ggplot(hr_cleaned, aes(monthly_income)) +
  geom_density() + 
  facet_wrap(~education) +
  theme_minimal()+
  labs(x = &quot;Monthly Income&quot;,
       y = &quot;&quot;)</code></pre>
<p><img src="/projects/project1/index_files/figure-html/unnamed-chunk-14-1.png" width="648" style="display: block; margin: auto;" /></p>
<ul>
<li>Plot income vs age, faceted by <code>job_role</code></li>
</ul>
<pre class="r"><code>ggplot(hr_cleaned, aes(x = age, y = monthly_income)) +
  geom_point() +
  geom_smooth(method = &quot;lm&quot;) +
  facet_wrap(~job_role) +
  labs(x = &quot;Age&quot;,
       y = &quot;Monthly Income&quot;)</code></pre>
<p><img src="/projects/project1/index_files/figure-html/unnamed-chunk-15-1.png" width="648" style="display: block; margin: auto;" /></p>
<blockquote>
<p>Summary:</p>
</blockquote>
<p>The first observation we can make from the data set is that the attrition rate i.e. the share of employees who left the company is 16.1%. Next, if we look at age, years at the company, monthly income and years since last promotion figures, we can see that of these, age seems to have the most normal distribution. The modal age of the employees is around 34 years, with a slight right skew, the median and mean ages seem to be slightly higher. The distribution of years at the company has a significant right skew, with a mode around 5 years and slight peaks around ‘milestone’ numbers like 10 or 20. This is intuitive as 5, 10 and 20 years may seem to employees as the optimal times to consider a career switch or retiring. The distribution of the monthly income also has a right skew with a modal income of around 3000. This can be linked to the number of employees at each seniority level. As there would be more employees of a more junior level, the modal income should be on the lower side of the income range. The distribution is similar for the years since last promotion, we can see that the majority of employees have been promoted within the last 3 years and very few work for over 8 years without being promoted. This could also be linked to the fact that, without a promotion for many years, employees would leave the company.</p>
<p>Now, if we look at job satisfaction, we would see a left-skewed distribution with the modal job satisfaction as ‘Very High’ with about 31% reporting this level, and a further 30% reporting ‘High’ satisfaction, implying that the majority of employees are happy with their jobs. The work-life balance seems to be slightly more normally distributed with the majority (~60%) reporting a ‘Better’ work-life balance. The distribution has a slight left skew as well, with only 10% reporting a ‘Best’ work-life balance to the right while 23% reporting ‘Good’ and 5% reporting ‘Bad’ to the left. But we can also see that &gt;90% are reporting a ‘Good’, ‘Better’, ‘Best’ work-life balance, implying an overall satisfaction with the work-life balance.</p>
<p>Returning back to monthly income, we can see a clear positive correlation between education level and mean income, with the mean income increasing consistently from 5640 at ‘Below College’ level to 8277 at ‘Doctor’ level. In addition, there seems to be no impact of additional education on the maximum pay, with maximum income between 19500 to 20000 regardless of education level. For the minimum income level, we can only see that ‘Master’ and ‘Doctor’ tend to affect the minimum income level, with the minimum income around 1000 for any education level below ‘Master’. For every level of education, the distribution has a right skew. However, the higher the level of education, the lower the peak of the density distribution, meaning that there is more variation in monthly income, the higher the education level. Moreover, median pay is slightly higher for Females than Males.</p>
<p>If we consider the income by role, we can see that the Manager and Research Director roles are the highest paid on average with Managers having a more consistent pay with a narrower interquartile range. We can also see that for each role the pay consistently increases with age, except for the roles of Laboratory Technician and Sales Representative where the pay seems to be relatively flat as age increases. In addition, the roles of Healthcare Representative, Research Director, Human Resources and Manager tend to have a steeper increase in pay as age increases, however, the variation in monthly pay at every age is higher too. This could be linked to education level and years in the company of employees at every age, as Technician and Sales Rep roles are more likely to be entry-level and hence have less variation.</p>
</div>
<div id="challenge-1-replicating-a-chart" class="section level1">
<h1>Challenge 1: Replicating a chart</h1>
<p>The purpose of this exercise is to make a publication-ready plot using your <code>dplyr</code> and <code>ggplot2</code> skills. Open the journal article “Riddell_Annals_Hom-Sui-Disparities.pdf”. Read the abstract and have a look at Figure 3. The data you need is “CDC_Males.csv”.</p>
<p><img src="C:/Users/Mark/Desktop/my_website/images/figure3.jpeg" width="90%" style="display: block; margin: auto;" /></p>
<p>Our attempt to get as far as we could:</p>
<p><img src="/projects/project1/index_files/figure-html/unnamed-chunk-16-1.png" width="648" style="display: block; margin: auto;" /></p>
</div>
<div id="challenge-2-2016-california-contributors-plots" class="section level1">
<h1>Challenge 2: 2016 California Contributors plots</h1>
<p>As discussed in class, I would like you to reproduce the plot that shows the top ten cities in highest amounts raised in political contributions in California during the 2016 US Presidential election.</p>
<p><img src="C:/Users/Mark/Desktop/my_website/images/challenge2.png" width="100%" style="display: block; margin: auto;" /></p>
<p>To get this plot, we must join two dataframes; the one we have with all contributions, and data that can translate zipcodes to cities.
Data on zip codes can be found here <a href="http://www.uszipcodelist.com/download.html" class="uri">http://www.uszipcodelist.com/download.html</a>.</p>
<p>The easiest way would be to create two plots and then place one next to each other. For this, we will need the <code>patchwork</code> package.
<a href="https://cran.r-project.org/web/packages/patchwork/index.html" class="uri">https://cran.r-project.org/web/packages/patchwork/index.html</a></p>
<pre class="r"><code># Make sure you use vroom() as it is significantly faster than read.csv()

CA_contributors_2016 &lt;- vroom::vroom(here::here(&quot;data&quot;,&quot;CA_contributors_2016.csv&quot;))
zip_code &lt;- vroom::vroom(here::here(&quot;data&quot;, &quot;zip_code_database.csv&quot;))
zip_code &lt;- select(zip_code, c(&quot;zip&quot;, &quot;primary_city&quot;))

figure &lt;- merge(CA_contributors_2016, zip_code, by.x = &quot;zip&quot;)
figure_2 &lt;- figure %&gt;% 
  filter(cand_nm %in% c(&quot;Clinton, Hillary Rodham&quot;, &quot;Trump, Donald J.&quot;))

figure_2 %&gt;%
    group_by(cand_nm, primary_city) %&gt;%
    summarise(ttl_contb = sum(contb_receipt_amt)) %&gt;% 
    top_n(10) %&gt;%
    ungroup %&gt;%
    mutate(cand_nm = as.factor(cand_nm),
           primary_city = reorder_within(primary_city, ttl_contb, cand_nm)) %&gt;%
    ggplot(aes(primary_city, ttl_contb, fill = cand_nm)) +
    geom_col(show.legend = FALSE) +
    facet_wrap(~cand_nm, scales = &quot;free&quot;) +
    coord_flip() +
    scale_x_reordered() +
    scale_y_continuous(labels=scales::dollar_format()) +
    theme_bw() +
    scale_fill_manual(values=c(&quot;#2f73bf&quot;, &quot;#cf444b&quot;)) +
    labs(y = &quot;Amount Raised&quot;,
         x = NULL,
         title = &quot;Where did candidates raise most money?&quot;)</code></pre>
<p><img src="/projects/project1/index_files/figure-html/load_CA_data-1.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code># # # Alternative approach to draw two graphs for candidates; Issue with patching them together arises at the end
# # Hillary Clinton Calculation
# col_gr &lt;- figure %&gt;% 
#   filter(cand_nm == &quot;Clinton, Hillary Rodham&quot;) %&gt;% 
#   group_by(primary_city) %&gt;% 
#   summarise(total_contb = sum(contb_receipt_amt)) %&gt;% 
#   arrange(desc(total_contb)) %&gt;% 
#   head(10) %&gt;% 
#   ggplot(aes(x = total_contb, y = fct_reorder(primary_city, total_contb))) +
#   geom_col(fill = &quot;blue&quot;) +
#   theme_bw() +
#   labs(title = &quot;Where did candidates raise most money?&quot;,
#        subtitle = &quot;Clinton, Hillary Rodham&quot;,
#        x = &quot;&quot;,
#        y = &quot;&quot;)
# 
# # Donald Trump Calculation
# col_gr_T &lt;- figure %&gt;% 
#   filter(cand_nm == &quot;Trump, Donald J.&quot;) %&gt;% 
#   group_by(primary_city) %&gt;% 
#   summarise(total_contb = sum(contb_receipt_amt)) %&gt;% 
#   arrange(desc(total_contb)) %&gt;% 
#   head(10) %&gt;% 
#   ggplot(aes(x = total_contb, y = fct_reorder(primary_city, total_contb))) +
#   geom_col(fill = &quot;red&quot;) +
#   theme_bw() +
#   labs(title = &quot;&quot;,
#        subtitle = &quot;Trump, Donald Jr.&quot;,
#        x = &quot;&quot;,
#        y = &quot;&quot;)
# 
# col_gr + col_gr_T</code></pre>
<p>While this is ok, what if one asked you to create the same plot for the top 10 candidates and not just the top two? The most challenging part is how to reorder within categories, and for this you will find Julia Silge’s post on <a href="https://juliasilge.com/blog/reorder-within/">REORDERING AND FACETTING FOR GGPLOT2</a> useful.</p>
<pre class="r"><code># # Potential code for first ten candidates
# 
# 
# tp_10_cnd &lt;- figure %&gt;% 
#   group_by(cand_nm) %&gt;% 
#   summarise(s = sum(contb_receipt_amt)) %&gt;% 
#   arrange(desc(s)) %&gt;% 
#   head(10)
# 
# tp_10_cnd
# 
# sum_data &lt;- figure %&gt;% 
#   filter(cand_nm == tp_10_cnd$cand_nm) %&gt;%
#   group_by(cand_nm, primary_city) %&gt;% 
#   summarise(ttl_contb = sum(contb_receipt_amt))
#   
# sum_data
# 
# sum_data %&gt;%
#     group_by(cand_nm) %&gt;%
#     top_n(10) %&gt;%
#     ungroup %&gt;%
#     mutate(cand_nm = as.factor(cand_nm),
#            primary_city = reorder_within(primary_city, ttl_contb, cand_nm)) %&gt;%
#     ggplot(aes(primary_city, ttl_contb, fill = cand_nm)) +
#     geom_col(show.legend = FALSE) +
#     facet_wrap(~cand_nm, scales = &quot;free&quot;, ncol = 5) +
#     coord_flip() +
#     scale_x_reordered() +
#     scale_y_continuous() +
#     labs(y = &quot;Amount Raised&quot;,
#          x = NULL,
#          title = &quot;Where did candidates raise most money?&quot;)</code></pre>
</div>
<div id="details" class="section level1">
<h1>Details</h1>
<ul>
<li>Who did you collaborate with: Benedikt Jaletzke, Stanislav Makarov, Mark Negodyuk, Tom Tian, Olivia Zhang, Kateryna Tarasova</li>
<li>Approximately how much time did you spend on this problem set: 7-8 hours</li>
<li>What, if anything, gave you the most trouble: Changing the size of the graphs; finding out new functions for formatting of graphs; bucketing the population size</li>
</ul>
</div>
